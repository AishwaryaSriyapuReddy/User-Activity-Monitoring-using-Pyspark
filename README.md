# User-Activity-Monitoring-using-Pyspark
Real-time analytics with Spark: User Activity Monitoring

## Project Overview
In this project, we’ll build a real-time data processing system that can handle information as it arrives — just like live updates on a sports scoreboard or stock prices. The aim is to recreate real-world streaming situations while learning important skills used by data engineers.

We’ll first set up a local environment to run our streaming system. Then, using Apache Spark Structured Streaming, we’ll process the incoming data instantly — filtering it, grouping it, and running queries on it as it flows in.

By the end, you’ll know how to handle late or out-of-order data, keep your system running even if something fails, and monitor its performance in Spark UI.

- Setting Up the Streaming Environment.
- Fault Tolerance with Checkpoints.
- Transformations in Streaming.
- Managing Late and Out-of-Order Data.
- SQL Queries on Streaming Data.
- Writing and Deploying the Pipeline.
